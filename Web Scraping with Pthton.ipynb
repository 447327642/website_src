{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is web scraping?\n",
    "\n",
    "Automated gathering of data from the Internet\n",
    "\n",
    "Bots are Web-scraping programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter1 Your first web scraper\n",
    "\n",
    "### What happens when send a get request to a server?\n",
    "\n",
    "1. generate a stream of 1 and 0 bit: header(an immediate destination of local router's MAC address, final destination IP address) & body(request fro server application)\n",
    "\n",
    "2. local router interprets them as a packet and router stamps its own IP address as \"From\" on the packet then sends it off\n",
    "\n",
    "3. intermediary servers\n",
    "\n",
    "4. destination server receivs the packet\n",
    "\n",
    "5. server reads the packet port destination and pass it to appropriate application\n",
    "\n",
    "6. web server application receive a stream of data from the server processor\n",
    "\n",
    "7. bundles needed info up into a new packet to send\n",
    "\n",
    "### How this is done in python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a virtual environment\n",
    "\n",
    "`virtualenv scrapingEnv`\n",
    "\n",
    "`cd scrapingEnv`\n",
    "\n",
    "`source bin/activate`\n",
    "\n",
    "`deactivate`\n",
    "\n",
    "Keeping all libraries separated by project. Easy to zip up thr entire environment folder. \n",
    "\n",
    "### Use beautifulsoup library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "bsObj = BeautifulSoup(html.read(), \"html.parser\")\n",
    "print(bsObj.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exception handling\n",
    "\n",
    "`html = urlopen(\"http://pythonscraping.com/pages/page1.html\")`\n",
    "\n",
    "Two main things that can go wrong in this line:\n",
    "\n",
    "- The page is not found on the server(or there was some error in retriving it)\n",
    "\n",
    "    - This may cause \"404 page not found\" or \"500 internal server error\", etc\n",
    "\n",
    "- The server is not found\n",
    "\n",
    "    - urlopen returns a none object\n",
    "    \n",
    "- If a tag does not exist\n",
    "\n",
    "    - BeautifulSoup will reutn a None object, AttributeError being thrown\n",
    "    \n",
    "**Refactor 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "try:\n",
    "    html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    if html is None:\n",
    "        print(\"URL is not found\")\n",
    "    else:\n",
    "        bsObj = BeautifulSoup(html.read(), \"html.parser\")\n",
    "        try:\n",
    "            title = bsObj.html.h1\n",
    "        except AttributeError as e:\n",
    "            print(\"Tag was not found\")\n",
    "        else:\n",
    "            if title == None:\n",
    "                print(\"Tag was not found\")\n",
    "            else:\n",
    "                print(bsObj.html.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refactor 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    else:\n",
    "        if html is None:\n",
    "            print(\"URL is not found\")\n",
    "        try:\n",
    "            bsObj = BeautifulSoup(html.read(), \"html.parser\")\n",
    "            title = bsObj.h1\n",
    "        except AttributeError as e:\n",
    "            return None\n",
    "        return title\n",
    "title = getTitle(\"http://pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title could not found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
